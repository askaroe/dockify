{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lifestyle Models Training: 2A, 2B, 2C\n",
        "\n",
        "Model 2A: Lifestyle Classifier\n",
        "Model 2B: Activity Predictor\n",
        "Model 2C: Health Risk Scorer\n",
        "Framework: MindSpore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:30:20.328.000 [mindspore/context.py:1402] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MindSpore version: 2.6.0\n",
            "Libraries imported successfully!\n",
            "Execution mode: PyNative (dynamic graph)\n",
            "Device: CPU\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error,\n",
        "                             accuracy_score, precision_recall_fscore_support, \n",
        "                             confusion_matrix, classification_report)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import mindspore\n",
        "from mindspore import nn, ops, Tensor, context\n",
        "from mindspore import save_checkpoint\n",
        "import mindspore.dataset as ds\n",
        "\n",
        "context.set_context(mode=context.PYNATIVE_MODE, device_target=\"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (20168, 121)\n",
            "\n",
            "Columns: 121 total\n",
            "Samples: 20168\n",
            "\n",
            "============================================================\n",
            "TARGET VARIABLES\n",
            "============================================================\n",
            "\n",
            "1. lifestyle_category (Model 2A - Classification):\n",
            "lifestyle_category\n",
            "active       10846\n",
            "sedentary     8303\n",
            "athletic      1019\n",
            "Name: count, dtype: int64\n",
            "\n",
            "2. next_day_calories_burned (Model 2B - Regression):\n",
            "count    20168.000000\n",
            "mean      1280.912615\n",
            "std        502.600894\n",
            "min        323.990000\n",
            "25%        910.800000\n",
            "50%       1232.115000\n",
            "75%       1554.072500\n",
            "max       2890.820000\n",
            "Name: next_day_calories_burned, dtype: float64\n",
            "\n",
            "3. health_risk_score (Model 2C - Regression):\n",
            "count    20168.000000\n",
            "mean        27.041303\n",
            "std         18.124198\n",
            "min          0.000000\n",
            "25%         14.000000\n",
            "50%         24.000000\n",
            "75%         38.000000\n",
            "max         76.000000\n",
            "Name: health_risk_score, dtype: float64\n",
            "\n",
            "Data loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../data/processed/lifestyle_processed.csv')\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(df['lifestyle_category'].value_counts())\n",
        "print(df['next_day_calories_burned'].describe())\n",
        "print(df['health_risk_score'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available features: 29\n",
            "Features (first 10): ['Age_scaled', 'Weight (kg)_scaled', 'Height (m)_scaled', 'BMI_scaled', 'Fat_Percentage_scaled', 'lean_body_mass_scaled', 'fat_mass_scaled', 'Max_BPM_scaled', 'Avg_BPM_scaled', 'Resting_BPM_scaled']\n",
            "\n",
            "============================================================\n",
            "FEATURE MATRIX PREPARATION\n",
            "============================================================\n",
            "Feature matrix shape: (20168, 29)\n",
            "Number of features: 29\n",
            "Number of samples: 20168\n",
            "\n",
            "Input dimension for all models: 29\n"
          ]
        }
      ],
      "source": [
        "feature_candidates = [\n",
        "    'Age_scaled', 'Weight (kg)_scaled', 'Height (m)_scaled', 'BMI_scaled',\n",
        "    'Fat_Percentage_scaled', 'lean_body_mass_scaled', 'fat_mass_scaled',\n",
        "    'Max_BPM_scaled', 'Avg_BPM_scaled', 'Resting_BPM_scaled',\n",
        "    'Session_Duration (hours)_scaled', 'Calories_Burned_scaled',\n",
        "    'Workout_Frequency (days/week)_scaled', 'workout_intensity',\n",
        "    'Carbs_scaled', 'Proteins_scaled', 'Fats_scaled', 'Calories_scaled',\n",
        "    'Water_Intake (liters)_scaled', 'protein_per_kg_scaled',\n",
        "    'heart_rate_reserve_scaled', 'training_intensity_scaled',\n",
        "    'calories_per_hour_scaled', 'water_per_kg_scaled',\n",
        "    'caloric_balance_scaled', 'weekly_activity_load_scaled',\n",
        "    'Experience_Level', 'Daily meals frequency', 'Physical exercise'\n",
        "]\n",
        "\n",
        "available_features = [col for col in feature_candidates if col in df.columns]\n",
        "X = df[available_features].fillna(0).values.astype(np.float32)\n",
        "input_dim = X.shape[1]\n",
        "print(f\"Features: {len(available_features)}, Input dim: {input_dim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2A: Lifestyle Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL 2A: LIFESTYLE CLASSIFICATION\n",
            "============================================================\n",
            "Target shape: (20168,)\n",
            "Number of classes: 3\n",
            "Class names: ['active', 'athletic', 'sedentary']\n",
            "\n",
            "Class distribution:\n",
            "  active: 10846 (53.8%)\n",
            "  athletic: 1019 (5.1%)\n",
            "  sedentary: 8303 (41.2%)\n",
            "\n",
            "Train: 16134 | Test: 4034\n"
          ]
        }
      ],
      "source": [
        "y_2a = df['lifestyle_category_encoded'].values.astype(np.int32)\n",
        "lifestyle_classes = sorted(df['lifestyle_category'].unique())\n",
        "num_classes_2a = len(lifestyle_classes)\n",
        "\n",
        "X_2a_train, X_2a_test, y_2a_train, y_2a_test = train_test_split(\n",
        "    X, y_2a, test_size=0.2, random_state=42, stratify=y_2a\n",
        ")\n",
        "print(f\"Train: {X_2a_train.shape[0]}, Test: {X_2a_test.shape[0]}, Classes: {num_classes_2a}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model 2A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:30:20.953.000 [mindspore/nn/layer/basic.py:176] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:30:20.955.000 [mindspore/nn/layer/basic.py:176] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:30:20.958.000 [mindspore/nn/layer/basic.py:176] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 2A Architecture: 29 → 128 → 64 → 32 → 3\n",
            "\n",
            "============================================================\n",
            "TRAINING MODEL 2A\n",
            "============================================================\n",
            "\n",
            "Epoch [ 1/80] Loss: 0.5373 Acc: 76.59%\n",
            "Epoch [10/80] Loss: 0.2788 Acc: 84.90%\n",
            "Epoch [20/80] Loss: 0.2637 Acc: 85.96%\n",
            "Epoch [30/80] Loss: 0.2319 Acc: 89.83%\n",
            "Epoch [40/80] Loss: 0.1976 Acc: 92.32%\n",
            "Epoch [50/80] Loss: 0.1669 Acc: 94.01%\n",
            "Epoch [60/80] Loss: 0.1470 Acc: 94.81%\n",
            "Epoch [70/80] Loss: 0.1481 Acc: 94.66%\n",
            "Epoch [80/80] Loss: 0.1375 Acc: 95.12%\n",
            "\n",
            "Training complete! Final accuracy: 95.12%\n"
          ]
        }
      ],
      "source": [
        "class LifestyleClassifier(nn.Cell):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LifestyleClassifier, self).__init__()\n",
        "        self.fc1 = nn.Dense(input_dim, 128)\n",
        "        self.fc2 = nn.Dense(128, 64)\n",
        "        self.fc3 = nn.Dense(64, 32)\n",
        "        self.fc4 = nn.Dense(32, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(keep_prob=0.7)\n",
        "        self.dropout2 = nn.Dropout(keep_prob=0.7)\n",
        "        self.dropout3 = nn.Dropout(keep_prob=0.8)\n",
        "        \n",
        "    def construct(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout3(x)\n",
        "        return self.fc4(x)\n",
        "\n",
        "model_2a = LifestyleClassifier(input_dim, num_classes_2a)\n",
        "lr_2a, epochs_2a, batch_size_2a = 0.001, 80, 64\n",
        "loss_fn_2a = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
        "optimizer_2a = nn.Adam(model_2a.trainable_params(), learning_rate=lr_2a)\n",
        "\n",
        "def forward_2a(data, label):\n",
        "    return loss_fn_2a(model_2a(data), label)\n",
        "\n",
        "grad_fn_2a = ops.value_and_grad(forward_2a, None, optimizer_2a.parameters)\n",
        "\n",
        "def train_step_2a(data, label):\n",
        "    loss, grads = grad_fn_2a(data, label)\n",
        "    optimizer_2a(grads)\n",
        "    return loss\n",
        "\n",
        "train_losses_2a = []\n",
        "train_accs_2a = []\n",
        "model_2a.set_train(True)\n",
        "\n",
        "for epoch in range(epochs_2a):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_correct = 0\n",
        "    epoch_total = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    for i in range(0, len(X_2a_train), batch_size_2a):\n",
        "        batch_X = Tensor(X_2a_train[i:i+batch_size_2a], mindspore.float32)\n",
        "        batch_y = Tensor(y_2a_train[i:i+batch_size_2a], mindspore.int32)\n",
        "        loss = train_step_2a(batch_X, batch_y)\n",
        "        epoch_loss += loss.asnumpy()\n",
        "        model_2a.set_train(False)\n",
        "        preds = model_2a(batch_X)\n",
        "        pred_classes = ops.argmax(preds, 1).asnumpy()\n",
        "        epoch_correct += (pred_classes == batch_y.asnumpy()).sum()\n",
        "        epoch_total += len(batch_y)\n",
        "        model_2a.set_train(True)\n",
        "        num_batches += 1\n",
        "    \n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    avg_acc = epoch_correct / epoch_total * 100\n",
        "    train_losses_2a.append(avg_loss)\n",
        "    train_accs_2a.append(avg_acc)\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1:2d}/{epochs_2a}] Loss: {avg_loss:.4f} Acc: {avg_acc:.2f}%\")\n",
        "\n",
        "print(f\"Final accuracy: {train_accs_2a[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate & Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL 2A EVALUATION\n",
            "============================================================\n",
            "Accuracy:  0.9460 (94.60%)\n",
            "Precision: 0.9579\n",
            "Recall:    0.9460\n",
            "F1-Score:  0.9492\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2001  132   36]\n",
            " [   2  202    0]\n",
            " [  48    0 1613]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      active       0.98      0.92      0.95      2169\n",
            "    athletic       0.60      0.99      0.75       204\n",
            "   sedentary       0.98      0.97      0.97      1661\n",
            "\n",
            "    accuracy                           0.95      4034\n",
            "   macro avg       0.85      0.96      0.89      4034\n",
            "weighted avg       0.96      0.95      0.95      4034\n",
            "\n",
            "\n",
            "✓ Model 2A saved to ../models/model_2A_lifestyle_classifier.ckpt\n"
          ]
        }
      ],
      "source": [
        "model_2a.set_train(False)\n",
        "y_2a_pred = ops.argmax(model_2a(Tensor(X_2a_test, mindspore.float32)), 1).asnumpy()\n",
        "\n",
        "acc_2a = accuracy_score(y_2a_test, y_2a_pred)\n",
        "prec_2a, rec_2a, f1_2a, _ = precision_recall_fscore_support(y_2a_test, y_2a_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {acc_2a:.4f}, Precision: {prec_2a:.4f}, Recall: {rec_2a:.4f}, F1: {f1_2a:.4f}\")\n",
        "print(confusion_matrix(y_2a_test, y_2a_pred))\n",
        "print(classification_report(y_2a_test, y_2a_pred, target_names=lifestyle_classes))\n",
        "\n",
        "import json\n",
        "save_checkpoint(model_2a, '../models/model_2A_lifestyle_classifier.ckpt')\n",
        "with open('../models/model_2A_metadata.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'model_name': 'Lifestyle Classifier (Model 2A)',\n",
        "        'model_type': 'Classification',\n",
        "        'framework': 'MindSpore',\n",
        "        'input_dim': input_dim,\n",
        "        'output_dim': num_classes_2a,\n",
        "        'classes': lifestyle_classes,\n",
        "        'metrics': {'accuracy': float(acc_2a), 'precision': float(prec_2a), 'recall': float(rec_2a), 'f1_score': float(f1_2a)}\n",
        "    }, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2B: Activity Predictor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train & Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:33:53.150.000 [mindspore/nn/layer/basic.py:176] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL 2B: ACTIVITY PREDICTOR (REGRESSION)\n",
            "============================================================\n",
            "Target: next_day_calories_burned\n",
            "Train: 16134 | Test: 4034\n",
            "Target range: [324, 2891]\n",
            "\n",
            "Training Model 2B...\n",
            "Epoch [ 1/80] Loss: 674076.4307\n",
            "Epoch [10/80] Loss: 24800.5288\n",
            "Epoch [20/80] Loss: 22456.1992\n",
            "Epoch [30/80] Loss: 20612.2045\n",
            "Epoch [40/80] Loss: 16499.6071\n",
            "Epoch [50/80] Loss: 12333.1120\n",
            "Epoch [60/80] Loss: 10928.5067\n",
            "Epoch [70/80] Loss: 10262.5051\n",
            "Epoch [80/80] Loss: 9489.3439\n",
            "\n",
            "============================================================\n",
            "MODEL 2B EVALUATION\n",
            "============================================================\n",
            "MSE:  39068.52\n",
            "RMSE: 197.66 calories\n",
            "MAE:  180.32 calories\n",
            "R²:   0.8428\n",
            "\n",
            "✓ Model 2B saved!\n"
          ]
        }
      ],
      "source": [
        "y_2b = df['next_day_calories_burned'].values.astype(np.float32).reshape(-1, 1)\n",
        "X_2b_train, X_2b_test, y_2b_train, y_2b_test = train_test_split(X, y_2b, test_size=0.2, random_state=42)\n",
        "\n",
        "class ActivityPredictor(nn.Cell):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ActivityPredictor, self).__init__()\n",
        "        self.fc1 = nn.Dense(input_dim, 128)\n",
        "        self.fc2 = nn.Dense(128, 64)\n",
        "        self.fc3 = nn.Dense(64, 32)\n",
        "        self.fc4 = nn.Dense(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(keep_prob=0.7)\n",
        "        \n",
        "    def construct(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "model_2b = ActivityPredictor(input_dim)\n",
        "lr_2b, epochs_2b, batch_size_2b = 0.001, 80, 64\n",
        "loss_fn_2b = nn.MSELoss()\n",
        "optimizer_2b = nn.Adam(model_2b.trainable_params(), learning_rate=lr_2b)\n",
        "\n",
        "def forward_2b(data, label):\n",
        "    return loss_fn_2b(model_2b(data), label)\n",
        "\n",
        "grad_fn_2b = ops.value_and_grad(forward_2b, None, optimizer_2b.parameters)\n",
        "\n",
        "def train_step_2b(data, label):\n",
        "    loss, grads = grad_fn_2b(data, label)\n",
        "    optimizer_2b(grads)\n",
        "    return loss\n",
        "\n",
        "train_losses_2b = []\n",
        "model_2b.set_train(True)\n",
        "\n",
        "for epoch in range(epochs_2b):\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for i in range(0, len(X_2b_train), batch_size_2b):\n",
        "        batch_X = Tensor(X_2b_train[i:i+batch_size_2b], mindspore.float32)\n",
        "        batch_y = Tensor(y_2b_train[i:i+batch_size_2b], mindspore.float32)\n",
        "        loss = train_step_2b(batch_X, batch_y)\n",
        "        epoch_loss += loss.asnumpy()\n",
        "        num_batches += 1\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    train_losses_2b.append(avg_loss)\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1:2d}/{epochs_2b}] Loss: {avg_loss:.4f}\")\n",
        "\n",
        "model_2b.set_train(False)\n",
        "y_2b_pred = model_2b(Tensor(X_2b_test, mindspore.float32)).asnumpy()\n",
        "mse_2b = mean_squared_error(y_2b_test, y_2b_pred)\n",
        "rmse_2b = np.sqrt(mse_2b)\n",
        "mae_2b = mean_absolute_error(y_2b_test, y_2b_pred)\n",
        "r2_2b = r2_score(y_2b_test, y_2b_pred)\n",
        "\n",
        "print(f\"MSE: {mse_2b:.2f}, RMSE: {rmse_2b:.2f}, MAE: {mae_2b:.2f}, R2: {r2_2b:.4f}\")\n",
        "\n",
        "save_checkpoint(model_2b, '../models/model_2B_activity_predictor.ckpt')\n",
        "with open('../models/model_2B_metadata.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'model_name': 'Activity Predictor (Model 2B)',\n",
        "        'model_type': 'Regression',\n",
        "        'framework': 'MindSpore',\n",
        "        'input_dim': input_dim,\n",
        "        'metrics': {'MSE': float(mse_2b), 'RMSE': float(rmse_2b), 'MAE': float(mae_2b), 'R2': float(r2_2b)}\n",
        "    }, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2C: Health Risk Scorer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train & Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING] ME(30938:128662946009216,MainProcess):2025-11-16-18:37:03.354.000 [mindspore/nn/layer/basic.py:176] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL 2C: HEALTH RISK SCORER (REGRESSION)\n",
            "============================================================\n",
            "Target: health_risk_score (0-100)\n",
            "Train: 16134 | Test: 4034\n",
            "Target range: [0.0, 76.0]\n",
            "Mean risk: 27.0\n",
            "\n",
            "Training Model 2C...\n",
            "Epoch [ 1/80] Loss: 238.4338\n",
            "Epoch [10/80] Loss: 41.9553\n",
            "Epoch [20/80] Loss: 34.2099\n",
            "Epoch [30/80] Loss: 27.3177\n",
            "Epoch [40/80] Loss: 23.5517\n",
            "Epoch [50/80] Loss: 20.9839\n",
            "Epoch [60/80] Loss: 19.7726\n",
            "Epoch [70/80] Loss: 18.5072\n",
            "Epoch [80/80] Loss: 17.3190\n",
            "\n",
            "============================================================\n",
            "MODEL 2C EVALUATION\n",
            "============================================================\n",
            "MSE:  31.92\n",
            "RMSE: 5.65 risk points\n",
            "MAE:  4.16 risk points\n",
            "R²:   0.9027\n",
            "\n",
            "✓ Model 2C saved!\n"
          ]
        }
      ],
      "source": [
        "y_2c = df['health_risk_score'].values.astype(np.float32).reshape(-1, 1)\n",
        "X_2c_train, X_2c_test, y_2c_train, y_2c_test = train_test_split(X, y_2c, test_size=0.2, random_state=42)\n",
        "\n",
        "class HealthRiskScorer(nn.Cell):\n",
        "    def __init__(self, input_dim):\n",
        "        super(HealthRiskScorer, self).__init__()\n",
        "        self.fc1 = nn.Dense(input_dim, 128)\n",
        "        self.fc2 = nn.Dense(128, 64)\n",
        "        self.fc3 = nn.Dense(64, 32)\n",
        "        self.fc4 = nn.Dense(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(keep_prob=0.7)\n",
        "        \n",
        "    def construct(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "model_2c = HealthRiskScorer(input_dim)\n",
        "lr_2c, epochs_2c, batch_size_2c = 0.001, 80, 64\n",
        "loss_fn_2c = nn.MSELoss()\n",
        "optimizer_2c = nn.Adam(model_2c.trainable_params(), learning_rate=lr_2c)\n",
        "\n",
        "def forward_2c(data, label):\n",
        "    return loss_fn_2c(model_2c(data), label)\n",
        "\n",
        "grad_fn_2c = ops.value_and_grad(forward_2c, None, optimizer_2c.parameters)\n",
        "\n",
        "def train_step_2c(data, label):\n",
        "    loss, grads = grad_fn_2c(data, label)\n",
        "    optimizer_2c(grads)\n",
        "    return loss\n",
        "\n",
        "train_losses_2c = []\n",
        "model_2c.set_train(True)\n",
        "\n",
        "for epoch in range(epochs_2c):\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for i in range(0, len(X_2c_train), batch_size_2c):\n",
        "        batch_X = Tensor(X_2c_train[i:i+batch_size_2c], mindspore.float32)\n",
        "        batch_y = Tensor(y_2c_train[i:i+batch_size_2c], mindspore.float32)\n",
        "        loss = train_step_2c(batch_X, batch_y)\n",
        "        epoch_loss += loss.asnumpy()\n",
        "        num_batches += 1\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    train_losses_2c.append(avg_loss)\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1:2d}/{epochs_2c}] Loss: {avg_loss:.4f}\")\n",
        "\n",
        "model_2c.set_train(False)\n",
        "y_2c_pred = model_2c(Tensor(X_2c_test, mindspore.float32)).asnumpy()\n",
        "mse_2c = mean_squared_error(y_2c_test, y_2c_pred)\n",
        "rmse_2c = np.sqrt(mse_2c)\n",
        "mae_2c = mean_absolute_error(y_2c_test, y_2c_pred)\n",
        "r2_2c = r2_score(y_2c_test, y_2c_pred)\n",
        "\n",
        "print(f\"MSE: {mse_2c:.2f}, RMSE: {rmse_2c:.2f}, MAE: {mae_2c:.2f}, R2: {r2_2c:.4f}\")\n",
        "\n",
        "save_checkpoint(model_2c, '../models/model_2C_health_risk_scorer.ckpt')\n",
        "with open('../models/model_2C_metadata.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'model_name': 'Health Risk Scorer (Model 2C)',\n",
        "        'model_type': 'Regression',\n",
        "        'framework': 'MindSpore',\n",
        "        'input_dim': input_dim,\n",
        "        'metrics': {'MSE': float(mse_2c), 'RMSE': float(rmse_2c), 'MAE': float(mae_2c), 'R2': float(r2_2c)}\n",
        "    }, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Model 2A: Lifestyle Classifier - models/model_2A_lifestyle_classifier.ckpt\n",
        "Model 2B: Activity Predictor - models/model_2B_activity_predictor.ckpt\n",
        "Model 2C: Health Risk Scorer - models/model_2C_health_risk_scorer.ckpt\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
